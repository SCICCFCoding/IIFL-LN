import argparse
import os
import shutil
import sys
sys.path.append('yolov7')

from mpi4py import MPI
import pandas as pd
import yaml

from node import Client, Node, Server


def init_node(rank: int, server_opt: str, server_lr: float, tau: float, beta: float) -> Node:
    """Initialize a node (client or server) based on its rank."""
    available_optimizers = ['fedavg', 'fedavgm', 'fedadagrad', 'fedadam', 'fedyogi']
    if server_opt not in available_optimizers:
        raise ValueError(f'Server optimizer {server_opt} unavailable, must be in {available_optimizers}.')
    if rank == 0:
        node = Server(server_opt, server_lr, tau, beta)
        node.use_immune_detection = args.use_immune_detection  
        if args.use_immune_detection:
            node.use_immune_detection = True
            node.detection_threshold = args.detection_threshold
            if args.trusted_clients:
                node.trusted_clients = [int(x) for x in args.trusted_clients.split(',')]
        return node
    else:
        attack_type = attack_types[rank-1] if len(attack_types) >= rank else 0
        return Client(rank, attack_type)

def share_public_keys(node: Node) -> None:
    """Clients receive the server's public key while the server receives each client's public key."""
    key_rank_pairs = comm.gather((node.rank, node.public_key), root=0)
    if node.rank == 0:
        key_rank_pairs = {r: cpk for r, cpk in key_rank_pairs}
        key_rank_pairs.pop(0)
        node.clients_public_keys = key_rank_pairs
    public_key = comm.bcast(node.public_key, root=0)
    if node.rank != 0:
        node.server_public_key = public_key

def share_symmetric_key(node: Node) -> None:
    """The symmetric key is generated by the server and shared among the clients using asymmetric encryption."""
    if node.rank == 0:
        node.generate_symmetric_key()
        sk = [None] + node.get_symmetric_key()
    else:
        sk = None
    sk = comm.scatter(sk, root=0)
    if node.rank != 0:
        node.symmetric_key = sk

def initial_broadcast(node: Node, pretrained_weights: str, data: str, cfg: str, hyp: str, imgsz: int) -> None:
    """The central server initializes the checkpoint from a pretrained weights file and shares it with the clients."""
    if node.rank == 0:
        node.initialize_model(pretrained_weights)
        encrypted_data = [None] + node.get_weights(metadata=True)
        node.post_init_update(data=data, cfg=cfg, hyp=hyp, imgsz=imgsz)
    else:
        encrypted_data = None
    encrypted_data = comm.scatter(encrypted_data, root=0)
    if node.rank != 0:
        node.set_weights(encrypted_data, metadata=True)

def federated_loop(node: Node, nrounds: int, epochs: int, saving_path: str, architecture: str, pretrained_weights: str,
                   data: str, bsz_train: int, bsz_val: int, imgsz: int, conf_thres: float, iou_thres: float, cfg: str,
                   hyp: str, workers: int) -> None:
    """Orchestrate the federated learning experiment."""
    for kround in range(nrounds):
        # At the beginning of a round, generate and share a new symmetric key
        share_symmetric_key(node)
        # If it is the first round, the central server sends the initial checkpoint to the clients
        if kround == 0:
            initial_broadcast(node, pretrained_weights, data, cfg, hyp, imgsz)
        # Client level computation (local training)
        if node.rank != 0:
            node.train(nrounds, kround, epochs, architecture, data, bsz_train, imgsz, cfg, hyp, workers, saving_path)
            sd_encrypted = node.get_update()
        else:
            sd_encrypted = None
        # Updates are gathered by the central server
        sd_encrypted = comm.gather(sd_encrypted, root=0)
        # Server level computation (server optimization, re-parameterization, and evaluation on the validation set)
        if node.rank == 0:
            sd_encrypted.pop(0)
            node.aggregate(sd_encrypted)
            if node.use_immune_detection:  
                detection = node.current_detection_result
                all_clients = detection["all_clients"]
                normal_clients = detection["normal_clients"]
                abnormal_clients = detection["abnormal_clients"]

                try:
                    true_abnormal = [cid for cid in all_clients if (cid - 1) < len(attack_types) and attack_types[cid - 1] != 0]
                except NameError:
                    true_abnormal = []
                detected_true = [cid for cid in abnormal_clients if cid in true_abnormal]
                Detection rate = len(detected_true) / len(true_abnormal) if true_abnormal else 0

                true_normal = [cid for cid in all_clients if cid not in true_abnormal]
                false_abnormal = [cid for cid in abnormal_clients if cid in true_normal]
                False positive rate = len(false_abnormal) / len(true_normal) if true_normal else 0

                log_msg = (
                    f"Round {kround}: Anomaly node detection results\n"
                    f"  All clients: {all_clients}\n"
                    f"  Normal clients: {normal_clients}\n"
                    f"  Abnormal clients: {abnormal_clients}\n"
                    f"  Detection rate: {detection_rate:.2%} (Number of detected true abnormal nodes: {len(detected_true)}/{len(true_abnormal)})\n"
                    f"  False positive rate: {false_positive_rate:.2%} (Number of falsely judged normal nodes: {len(false_abnormal)}/{len(true_normal)})\n"
                )
                print(log_msg)
                log_path = os.path.join(saving_path, "immune_detection_log.txt")
                with open(log_path, "a") as f:
                    f.write(log_msg + "\n")
            node.reparameterize(architecture)
            node.test(kround, saving_path, data, bsz_val, imgsz, conf_thres, iou_thres)
            sd_encrypted = [None] + node.get_weights(metadata=False)
            # gather_analytics(saving_path,node,kround)
        else:
            sd_encrypted = None
        # New weights are shared with the clients
        sd_encrypted = comm.scatter(sd_encrypted, root=0)
        if node.rank != 0:
            node.set_weights(sd_encrypted, metadata=False)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--nrounds', type=int, default=30, help='number of communication rounds')
    parser.add_argument('--epochs', type=int, default=5, help='number of epochs executed per communication round')
    parser.add_argument('--server-opt', type=str, default='fedavg', help='aggregation algorithm/server-side optimizer')
    parser.add_argument('--server-lr', type=float, default=1., help='server learning rate')
    parser.add_argument('--tau', type=float, default=1e-3, help='server adaptivity for FedAdagrad, FedAdam and FedYogi')
    parser.add_argument('--beta', type=float, default=0.1, help='server momentum with FedAvgM')
    parser.add_argument('--architecture', type=str, default='yolov7', help='model architecture')
    parser.add_argument('--weights', type=str, help='path to pretrained weights')
    parser.add_argument('--data', type=str, help='*.data path')
    parser.add_argument('--bsz-train', type=int, default=4, help='batch size used for training')
    parser.add_argument('--bsz-val', type=int, default=4, help='batch size used for evaluation')
    parser.add_argument('--img', type=int, default=640, help='inference size (pixels)')
    parser.add_argument('--conf', type=float, default=0.001, help='object confidence threshold')
    parser.add_argument('--iou', type=float, default=0.65, help='IOU threshold for NMS')
    parser.add_argument('--cfg', type=str, default='yolov7/cfg/training/yolov7.yaml', help='model.yaml path')
    parser.add_argument('--hyp', type=str, help='hyperparameters path, also decides client-side optimizer')
    parser.add_argument('--workers', type=int, default=8, help='number of workers to use during training')
    parser.add_argument('--use-immune-detection', action='store_true',default=False, help='whether to use immune negative selection test')
    parser.add_argument('--detection-threshold', type=float, default=0.8, help='anomaly detection threshold')
    parser.add_argument('--trusted-clients', type=str, default='1,3,5', help='list of trusted client IDs, separated by commas')
    parser.add_argument('--client-attack-types', type=str, default='0,1,1,0,0', help='Client attack types')
    args = parser.parse_args()

    if args.client_attack_types:
        attack_types = [int(x) for x in args.client_attack_types.split(',')]
    else:
        attack_types = []

    # Initialize MPI
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    node = init_node(rank, args.server_opt, args.server_lr, args.tau, args.beta)
    node.get_device_info()

    # Save the number of training examples held by the clients to perform weighted average aggregation of the updates
    with open(args.data) as f:
        if node.rank != 0:
            img_path = os.path.join(yaml.load(f, Loader=yaml.SafeLoader)['train'], f'client{node.rank}', 'images')
            node.nsamples = len(os.listdir(img_path))

    # The clients exchange their public keys with the central server and vice-versa
    share_public_keys(node)

    # Create saving folder
    saving_path = 'experiments90'
    os.makedirs(saving_path, exist_ok=True)
    os.makedirs(saving_path + '/weights/', exist_ok=True)
    os.makedirs(saving_path + '/run/', exist_ok=True)

    # Save config, cfg, hyp and data files
    if node.rank == 0:
        with open(saving_path + '/config.txt', 'w') as f:
            f.write(f'nrounds: {args.nrounds}\n')
            f.write(f'epochs: {args.epochs}\n')
            f.write(f'server opt: {args.server_opt}\n')
            f.write(f'server learning rate: {args.server_lr}\n')
            if args.server_opt == 'fedavgm':
                f.write(f'fedavgm - beta: {args.beta}\n')
            if args.server_opt == 'fedadagrad':
                f.write(f'fedadagrad - tau: {args.tau}\n')
            if args.server_opt in ['fedadam', 'fedyogi']:
                f.write(f'{args.server_opt} - tau: {args.tau}\n')
                f.write(f'{args.server_opt} - beta1: {0.9}\n')
                f.write(f'{args.server_opt} - beta2: {0.99}\n')
            f.write(f'architecture: {args.architecture}\n')
            f.write(f'weights: {args.weights}\n')
            f.write(f'data: {args.data}\n')
            f.write(f'batch size (train): {args.bsz_train}\n')
            f.write(f'batch size (eval): {args.bsz_val}\n')
            f.write(f'img: {args.img}\n')
            f.write(f'conf: {args.conf}\n')
            f.write(f'iou: {args.iou}\n')
            f.write(f'cfg: {args.cfg}\n')
            f.write(f'hyp: {args.hyp}\n')
            f.write(f'workers: {args.workers}\n')
        shutil.copy(args.cfg, saving_path)
        shutil.copy(args.hyp, saving_path)
        shutil.copy(args.data, saving_path)

    # Launch federated learning experiment
    federated_loop(
        node=node,
        nrounds=args.nrounds,
        epochs=args.epochs,
        saving_path=saving_path,
        architecture=args.architecture,
        pretrained_weights=args.weights,
        data=args.data,
        bsz_train=args.bsz_train,
        bsz_val=args.bsz_val,
        imgsz=args.img,
        conf_thres=args.conf,
        iou_thres=args.iou,
        cfg=args.cfg,
        hyp=args.hyp,
        workers=args.workers
    )
